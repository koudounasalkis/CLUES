{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db905f0a",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-information",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:44.908897Z",
     "start_time": "2022-04-20T15:20:44.883774Z"
    },
    "id": "powered-information"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-doctor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:45.349495Z",
     "start_time": "2022-04-20T15:20:44.910825Z"
    },
    "id": "built-doctor"
   },
   "outputs": [],
   "source": [
    "import divexplorer \n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils_analysis import plotMultipleSV, plotShapleyValue\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c80058f0",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26247e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for sorting data cohorts\n",
    "def sortItemset(x, abbreviations={}):\n",
    "    x = list(x)\n",
    "    x.sort()\n",
    "    x = \", \".join(x)\n",
    "    for k, v in abbreviations.items():\n",
    "        x = x.replace(k, v)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_in_itemset(itemset, attributes, alls = True):\n",
    "    \"\"\" Check if attributes are in the itemset (all or at least one)\n",
    "    \n",
    "    Args:\n",
    "        itemset (frozenset): the itemset\n",
    "        attributes (list): list of itemset of interest\n",
    "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
    "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Avoid returning the empty itemset (i.e., info of entire dataset)\n",
    "    if itemset == frozenset() and attributes:\n",
    "        return False\n",
    "    \n",
    "    for item in itemset:\n",
    "        # Get the attribute\n",
    "        attr_i = item.split(\"=\")[0]\n",
    "        \n",
    "        #If True, check if ALL attributes of the itemset are the input attributes.\n",
    "        if alls:\n",
    "            # Check if the attribute is present. If not, the itemset is not admitted\n",
    "            if attr_i not in attributes:\n",
    "                return False\n",
    "        else:\n",
    "            # Check if least one attribute. If yes, return True\n",
    "            if attr_i in attributes:\n",
    "                return True\n",
    "    if alls:\n",
    "        # All attributes of the itemset are indeed admitted\n",
    "        return True\n",
    "    else:\n",
    "        # Otherwise, it means that we find None\n",
    "        return False\n",
    "    \n",
    "def filter_itemset_df_by_attributes(df: pd.DataFrame, attributes: list, alls = True, itemset_col_name: str = \"itemsets\") -> pd.DataFrame:\n",
    "    \"\"\"Get the set of itemsets that have the attributes in the input list (all or at least one)\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): the input itemsets (with their info). \n",
    "        attributes (list): list of itemset of interest\n",
    "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
    "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
    "        itemset_col_name (str) : the name of the itemset column, \"itemsets\" as default\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: the set of itemsets (with their info)\n",
    "    \"\"\"\n",
    "\n",
    "    return df.loc[df[itemset_col_name].apply(lambda x: attributes_in_itemset(x, attributes, alls = alls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d02de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define abbreviations for plot and visualization\n",
    "from divexplorer.FP_Divergence import abbreviateDict\n",
    "abbreviations = {'Self-reported fluency level=native': 'fluency=native', \\\n",
    "                  'total_silence':'tot_silence', 'location': 'loc', \\\n",
    "                  'Current language used for work/school=English (United States)': 'lang=EN_US', \\\n",
    "                  'ageRange': 'age', \\\n",
    "                  'speakerId' : 'spkID', \\\n",
    "                  'First Language spoken=English (United States)':  'lang=EN_US', \\\n",
    "                  'trimmed': 'trim', \\\n",
    "                  'total_': 'tot_', \\\n",
    "                  'speed_rate_word':'speakRate', \\\n",
    "                  'speed_rate_char':'speakCharRate', \\\n",
    "                  'change language': 'change lang', \\\n",
    "                  'duration': 'dur'}\n",
    "\n",
    "abbreviations_shorter = abbreviations.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "occupational-madrid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:07:23.652910Z",
     "start_time": "2022-04-20T15:07:23.612488Z"
    },
    "id": "occupational-madrid"
   },
   "source": [
    "# Define targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461193a2",
   "metadata": {
    "id": "461193a2"
   },
   "outputs": [],
   "source": [
    "## Target for DivExplorer: \n",
    "# 'prediction' is 1 if predicted_intent == original_intent, 0 otherwise\n",
    "target_col = 'prediction' \n",
    "target_metric = 'd_posr'\n",
    "target_div = 'd_accuracy'\n",
    "t_value_col = 't_value_tp_fn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa3b44",
   "metadata": {
    "id": "8efa3b44"
   },
   "outputs": [],
   "source": [
    "## Columns for visualization\n",
    "show_cols = ['support', 'itemsets', '#errors', '#corrects', 'accuracy', \\\n",
    "                'd_accuracy', 't_value', 'support_count', 'length']\n",
    "remapped_cols = {'tn': '#errors', 'tp': '#corrects', 'posr': 'accuracy', \\\n",
    "                target_metric: target_div, 't_value_tp_fn': 't_value'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbd447",
   "metadata": {},
   "source": [
    "# FSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e257bab",
   "metadata": {},
   "source": [
    "## Retrieve Data and Compute Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
    "from divexplorer.FP_Divergence import FP_Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b043ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns of the df file that we are going to analyze \n",
    "demo_cols = ['Self-reported fluency level ', 'First Language spoken',\n",
    "       'Current language used for work/school', 'gender', 'ageRange']\n",
    "\n",
    "slot_cols = ['action', 'object', 'location']\n",
    "\n",
    "signal_cols = ['total_silence', 'total_duration', 'trimmed_duration', \n",
    "       'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'] \n",
    "signal_cols = ['total_silence', 'total_duration', 'n_words', 'speed_rate_word',] \n",
    "\n",
    "input_cols = demo_cols + signal_cols + slot_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66552fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"divexplorer\" # \"divexplorer\" or \"clustering\"\n",
    "\n",
    "## Define the minimum support threshold for data subgroups\n",
    "min_sup = 0.03\n",
    "\n",
    "configs = [\n",
    "    \"original\", \n",
    "    \"contrastive_intents\",\n",
    "    \"contrastive_subgroups\",\n",
    "    \"contrastive_subgroups_errors\",\n",
    "    \"contrastive_subgroups_errors_star\",\n",
    "    \"clues\",\n",
    "    \"augmentation\",\n",
    "    \"adversarial\",\n",
    "    \"acquisition\",\n",
    "    ]\n",
    "\n",
    "FP_fm_dict = {}\n",
    "fp_divergence_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    input_file_divexplorer = os.path.join(\\\n",
    "        os.getcwd(), \"results\", \"fsc\", config, \"42\", \"df_test.csv\")\n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "\n",
    "    ## Add SpeakerID information if it is present in the df\n",
    "    if \"speakerId\" in input_cols:\n",
    "        df['speakerId'] = df.index.map(lambda x: x.split(\"/\")[2])\n",
    "\n",
    "    ## Discretize the dataframe\n",
    "    from divergence_utils import discretize\n",
    "\n",
    "    df_discretized = discretize(\n",
    "        df[input_cols+[target_col]],\n",
    "        bins=3,\n",
    "        attributes=input_cols,\n",
    "        strategy=\"quantile\", \n",
    "        round_v = 2,\n",
    "        min_distinct=5,\n",
    "    )\n",
    "\n",
    "    ## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
    "    replace_values = {}\n",
    "\n",
    "    for i in range(0,len(signal_cols)):\n",
    "\n",
    "        for v in df_discretized[signal_cols[i]].unique():\n",
    "            if \"<=\" == v[0:2]:\n",
    "                replace_values[v] = \"low\"\n",
    "            elif \">\" == v[0]:\n",
    "                replace_values[v] = \"high\"\n",
    "            elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
    "                replace_values[v] = \"medium\"\n",
    "            else:\n",
    "                raise ValueError(v)\n",
    "\n",
    "        df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
    "    \n",
    "    df_discretized.loc[df_discretized[\"location\"]==\"none_location\", \"location\"] = \"none\"\n",
    "    df_discretized.loc[df_discretized[\"object\"]==\"none_object\", \"object\"] = \"none\"\n",
    "    \n",
    "    ## Create dict of Divergence df\n",
    "    df_dict[config] = df_discretized\n",
    "    fp_diver = FP_DivergenceExplorer(\n",
    "        df_discretized, \n",
    "        true_class_name=target_col, \n",
    "        class_map={\"P\":1, \"N\":0}\n",
    "        )\n",
    "    FP_fm = fp_diver.getFrequentPatternDivergence(\n",
    "        min_support=min_sup, \n",
    "        metrics=[target_metric]\n",
    "        )\n",
    "    FP_fm.rename(\n",
    "        columns=remapped_cols, \n",
    "        inplace=True\n",
    "        )\n",
    "    FP_fm = FP_fm[show_cols].copy()\n",
    "    FP_fm['accuracy'] = round(FP_fm['accuracy'], 5)\n",
    "    FP_fm['d_accuracy'] = round(FP_fm['d_accuracy'], 5)\n",
    "    FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
    "    FP_fm_dict[config] = FP_fm\n",
    "    fp_divergence_dict[config] = FP_Divergence(FP_fm, target_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857d9ad",
   "metadata": {},
   "source": [
    "## Divergence wav2vec 2.0 base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_redundancy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805595c",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base\n",
    "config = 'original'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdce4de",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Contrastive Intents ($L_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5229db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ contrastive learning on intents\n",
    "config = 'contrastive_intents'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c80186",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Contrastive Subgroups ($L_s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ L_i + L_s \n",
    "config = 'contrastive_subgroups'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67fb34",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Contrastive Subgroups + Errors ($L_s$ + $L_e$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbed4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ L_s + L_e \n",
    "config = 'contrastive_subgroups_errors'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90262336",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Contrastive Subgroups + Errors* ($L_s$ + $L_e^*$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ L_s + L_e*\n",
    "config = 'contrastive_subgroups_errors_star'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a441a",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ CLUES ($L_i$ + $L_s$ + $L_e$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bcd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ CLUES \n",
    "config = 'clues'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defab22c",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 w/ data augmentation\n",
    "config = 'augmentation'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda825f",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ adversarial loss\n",
    "config = 'adversarial'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d46535",
   "metadata": {},
   "source": [
    "### wav2vec 2.0 w/ Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ targeted acquisition \n",
    "config = 'acquisition'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7d20f",
   "metadata": {},
   "source": [
    "# ITALIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef4184",
   "metadata": {},
   "source": [
    "## Retrieve Data and Compute Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
    "from divexplorer.FP_Divergence import FP_Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns of the df file that we are going to analyze \n",
    "demo_cols = ['gender', 'age', 'region', 'nationality', 'lisp', 'education']\n",
    "\n",
    "slot_cols = ['action', 'scenario']\n",
    "\n",
    "rec_set_cols = ['environment', 'device', 'field']\n",
    "\n",
    "signal_cols = ['total_silence', 'total_duration', 'trimmed_duration', \n",
    "    'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'] \n",
    "\n",
    "input_cols = demo_cols + slot_cols + rec_set_cols + signal_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"divexplorer\" \n",
    "min_sup = 0.03\n",
    "\n",
    "configs = [\n",
    "    \"original\", \n",
    "    \"contrastive_intents\",\n",
    "    \"contrastive_subgroups\",\n",
    "    \"contrastive_subgroups_errors\",\n",
    "    \"contrastive_subgroups_errors_star\",\n",
    "    \"clues\",\n",
    "    \"augmentation\",\n",
    "    \"adversarial\",\n",
    "    \"acquisition\",\n",
    "    ]\n",
    "\n",
    "FP_fm_dict = {}\n",
    "fp_divergence_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    ## Read csv file\n",
    "    input_file_divexplorer = os.path.join(\\\n",
    "        os.getcwd(), \"results\", \"italic\", config, \"42\", \"df_test.csv\")                \n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "\n",
    "    ## create scenario and action columns from intent\n",
    "    df[\"scenario\"] = df[\"intent\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    df[\"action\"] = df[\"intent\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "    ## Discretize the dataframe\n",
    "    from divergence_utils import discretize\n",
    "\n",
    "    df_discretized = discretize(\n",
    "        df[input_cols+[target_col]],\n",
    "        bins=3,\n",
    "        attributes=input_cols,\n",
    "        strategy=\"quantile\", \n",
    "        round_v = 2,\n",
    "        min_distinct=5,\n",
    "    )\n",
    "\n",
    "    ## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
    "    replace_values = {}\n",
    "\n",
    "    for i in range(0,len(signal_cols)):\n",
    "\n",
    "        for v in df_discretized[signal_cols[i]].unique():\n",
    "            if \"<=\" == v[0:2]:\n",
    "                replace_values[v] = \"low\"\n",
    "            elif \">\" == v[0]:\n",
    "                replace_values[v] = \"high\"\n",
    "            elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
    "                replace_values[v] = \"medium\"\n",
    "            else:\n",
    "                raise ValueError(v)\n",
    "\n",
    "        df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
    "\n",
    "    ## Create dict of Divergence df\n",
    "    df_dict[config] = df_discretized\n",
    "    fp_diver = FP_DivergenceExplorer(\n",
    "        df_discretized, \n",
    "        true_class_name=target_col, \n",
    "        class_map={\"P\":1, \"N\":0}\n",
    "        )\n",
    "    FP_fm = fp_diver.getFrequentPatternDivergence(\n",
    "        min_support=min_sup, \n",
    "        metrics=[target_metric]\n",
    "        )\n",
    "    FP_fm.rename(\n",
    "        columns=remapped_cols, \n",
    "        inplace=True\n",
    "        )\n",
    "    FP_fm = FP_fm[show_cols].copy()\n",
    "    FP_fm['accuracy'] = round(FP_fm['accuracy'], 5)\n",
    "    FP_fm['d_accuracy'] = round(FP_fm['d_accuracy'], 5)\n",
    "    FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
    "    FP_fm_dict[config] = FP_fm\n",
    "    fp_divergence_dict[config] = FP_Divergence(FP_fm, target_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the accuracy of the models\n",
    "for config in configs:\n",
    "    prediction = df_dict[config]['prediction'].sum()/len(df_dict[config])\n",
    "    print(f\"Accuracy of {config}:\", round(100*prediction,3))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9671b",
   "metadata": {},
   "source": [
    "## Divergence XLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_redundancy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be40b9",
   "metadata": {},
   "source": [
    "### XLSR Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a829ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR\n",
    "config = 'original'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be50052",
   "metadata": {},
   "source": [
    "### XLSR w/ Contrastive Intents ($L_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ contrastive learning on intents\n",
    "config = 'contrastive_intents'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e58a1",
   "metadata": {},
   "source": [
    "### XLSR w/ Contrastive Subgroups ($L_s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad7138",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ L_i + L_s \n",
    "config = 'contrastive_subgroups'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33f530",
   "metadata": {},
   "source": [
    "### XLSR w/ Contrastive Subgroups + Errors ($L_s$ + $L_e$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545df95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ L_s + L_e \n",
    "config = 'contrastive_subgroups_errors'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ea65b",
   "metadata": {},
   "source": [
    "### XLSR w/ Contrastive Subgroups + Errors* ($L_s$ + $L_e^*$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ L_s + L_e*\n",
    "config = 'contrastive_subgroups_errors_star'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84a2ac",
   "metadata": {},
   "source": [
    "### XLSR w/ CLUES ($L_i$ + $L_s$ + $L_e$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ CLUES \n",
    "config = 'clues'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955b691",
   "metadata": {},
   "source": [
    "### XLSR w/ Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf90420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ data augmentation\n",
    "config = 'augmentation'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96399f",
   "metadata": {},
   "source": [
    "### XLSR w/ Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ adversarial loss\n",
    "config = 'adversarial'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de346c6e",
   "metadata": {},
   "source": [
    "### XLSR w/ Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ecfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR w/ targeted acquisition \n",
    "config = 'acquisition'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "print(\"Total negative subgroups: \", len(FPdiv[FPdiv['d_accuracy'] <= 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(5).copy()\n",
    "print(\"Mean negative divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(10).copy()\n",
    "print(\"Mean negative divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(20).copy()\n",
    "print(\"Mean negative divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(50).copy()\n",
    "print(\"Mean negative divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].copy()\n",
    "print(\"Mean negative divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "\n",
    "## Retrieve Most Positively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy) \n",
    "pr_top = FPdiv.head(n).copy()\n",
    "pr_top[\"support\"] = pr_top[\"support\"].round(2)\n",
    "pr_top[\"#errors\"] = pr_top[\"#errors\"].astype(int)\n",
    "pr_top[\"#corrects\"] = pr_top[\"#corrects\"].astype(int)\n",
    "pr_top[\"accuracy\"] = (pr_top[\"accuracy\"]*100).round(3)\n",
    "pr_top[\"d_accuracy\"] = (pr_top[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_top = pr_top[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_top['itemsets'] = pr_l_top['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_top)\n",
    "\n",
    "## Compute the mean positive divergence\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "print(\"Total positive subgroups: \", len(FPdiv[FPdiv['d_accuracy'] > 0]))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(5).copy()\n",
    "print(\"Mean positive divergence top 5:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(10).copy()\n",
    "print(\"Mean positive divergence top 10:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(20).copy()\n",
    "print(\"Mean positive divergence top 20:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].head(50).copy()\n",
    "print(\"Mean positive divergence top 50:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv[FPdiv['d_accuracy'] > 0].copy()\n",
    "print(\"Mean positive divergence all:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "pr = FPdiv.copy()\n",
    "print(\"\\nMean divergence all:\", round(100*pr['d_accuracy'].mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DivExplorer_FSC_IC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('speech': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "313.76837158203125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "50f798c039f92e39594af06ec0119751541d975fa6ec3b2f5528645cd2e370ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
